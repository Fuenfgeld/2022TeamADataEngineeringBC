{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copie de DataVault.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fuenfgeld/2022TeamADataEngineeringBC/blob/main/DataVault.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Vault"
      ],
      "metadata": {
        "id": "SJfNzSUY3aLE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Introduction\n",
        "\n",
        "According to Wikipedia \n",
        "> Data vault modeling is a database modeling method that is designed to provide long-term   historical storage of data coming in from multiple operational systems. \n",
        "\n",
        "In other words, data vault is a modelling technique which allows us to import all (structured) raw data into a database without the need to clean or alter the data. The data vault's main purpose is to store the unprocessed raw data long-term without the need to alter the data once it has been imported.\n",
        "\n",
        "All data that is imported into a data vault shall never be altered. Even schema changes in a source system can be modelled in a data vault without the need to adjust and update historical data.\n",
        "\n",
        "**Important:** A data vault's purpose is to collect data from OLTP systems and save it. The data vault is **never** used as an OLTP system.\n",
        "\n",
        "### 1.1. Benefits\n",
        "\n",
        "1. Long-term storage of data - As described in the introduction, a data vault model allows for a change resistant data schema. The schema can handle changes in data, changes in data source and changes in the schemas of source systems.\n",
        "2. Tracking data changes - The data vault tracks every single data change within a source system, even if the source system does not implement a change detection itself. The data vault not only detects changes but also when these changes occur, which make the system well suited if a dataset is supposed to be audible.\n",
        "3. Fast import of data - Another almost accidental benefit of the data vault is that data can be imported very quickly. Since a data vault always has a pre-existing version of a dataset, only the changes need to be synchronized, leading to a high import performance.\n",
        "4. Changes in data schemas do not necessarily required downstream ETL and analysis processes to be adjusted. - Since the data vault handles alterations of the source schemas very well, downstream ETL processes might not have to be adjusted. In most cases the conversion of the source data schema into the data vault schema will swallow all schema changes (while keeping all data) and thereby provide a stable interface for downstream ETL and analysis processes.\n",
        "\n",
        "### 1.2. Drawbacks\n",
        "\n",
        "1. Not easy to query - The data vault modeling creates rather complex schemas, which make is hard to query data. A simple data table with an identifier and some data will be projected onto multiple tables in the data vault context. Thereby, reading from a data vault becomes rather difficult.\n",
        "2. Large overhead - As the previous point already leads on, a data vault is rather complex and has a lot of overhead. This is due to the fact, that the data vault is meant to be resistant to changes. Therefore, relationships, data and identifiers are split into separate tables, thus creating a much higher complexity than exists in any of the source systems."
      ],
      "metadata": {
        "id": "fHi5JxNwI04Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Modeling"
      ],
      "metadata": {
        "id": "b3bEZY3n392c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To explain a model, we will take two simple tables which are connected by a relationship.\n",
        "\n",
        "```\n",
        "crops:\n",
        "+------+----------+-------------------+\n",
        "| id   | crop     | water_consumption |\n",
        "+------+----------+-------------------+\n",
        "| C-1  | tomato   | 10                |\n",
        "+------+----------+-------------------+\n",
        "| C-2  | cucumber | 15                |\n",
        "+------+----------+-------------------+\n",
        "\n",
        "fields:\n",
        "+------+-------+----------+\n",
        "| id   | field | crop_id  |\n",
        "+------+-------+----------+\n",
        "| F-5  | small | 2        |\n",
        "+------+-------+----------+\n",
        "| F-6  | big   | 1        |\n",
        "+------+-------+----------+\n",
        "```\n",
        "\n",
        "As you can see, we have a table which contains crops that we are growing and a table with our fields. Since each field has one crop growing on it, the tables have a n to 1 relationship.\n",
        "\n",
        "### 2.1. Hubs - Separating business keys\n",
        "\n",
        "The first thing we do to convert our source model into a data vault model is to extract the business keys into their own table. In addition to the business keys, we also save the source system as well as the load date and some other information.\n",
        "\n",
        "To simplify our example, we will take only a small amount of the fields for our demonstration. If you want to see all the other fields which should be saved on a hub, please refer to the data vault book.\n",
        "\n",
        "```\n",
        "crops hub:\n",
        "\n",
        "+----------+----------+------------+---------------+\n",
        "| hash_key | crop_key | load_date  | record_source |\n",
        "+----------+----------+------------+---------------+\n",
        "| b519e    | C-1      | 2022-05-01 | ERP           |\n",
        "+----------+----------+------------+---------------+\n",
        "| 5f763    | C-2      | 2022-05-01 | ERP           |\n",
        "+----------+----------+------------+---------------+\n",
        "```\n",
        "\n",
        "The hash key is used so that the importing system can easily check if a key has already been imported. Please also note that there is no `id` field. The primary key is the `hash_key` here.\n",
        "\n",
        "### 2.2. Satellites - Importing the data\n",
        "\n",
        "Since we split apart the business keys from the data, we still need to import the data. That is done using a satellite which contains all columns from the source table as well as a few additional columns: the load date, end date, hash diff.\n",
        "\n",
        "Satellites will never contain relationship data. Therefore, in case of the `fields` table, the `crop_id` column would be dropped here. Additionally, every data column needs to be nullable to allow for later changes in the data schema.\n",
        "\n",
        "```\n",
        "crops satelite:\n",
        "+---------------+----------+-------------------+------------+----------+---------------+-----------+\n",
        "| crop_hash_key | crop     | water_consumption | load_date  | end_date | record_source | hash_diff |\n",
        "+---------------+----------+-------------------+------------+----------+---------------+-----------+\n",
        "| b519e         | tomate   | 10                | 2022-05-01 | NULL     | ERP           | 8a3f0     |\n",
        "+---------------+----------+-------------------+------------+----------+---------------+-----------+\n",
        "| 5f763         | cucumber | 15                | 2022-05-01 | NULL     | ERP           | c345a     |\n",
        "+---------------+----------+-------------------+------------+----------+---------------+-----------+\n",
        "```\n",
        "\n",
        "The primary key is a multi column key using the `hash_key` and the `load_date` columns.\n",
        "\n",
        "### 2.3. Links - Saving relationships between tables\n",
        "\n",
        "Finally, we will save the relationship between the tables. This is done in another table.\n",
        "\n",
        "```\n",
        "crops fields link:\n",
        "+---------------------+---------------+----------------+------------+---------------+\n",
        "| field_crop_hash_key | crop_hash_key | field_hash_key | load_date  | record_source |\n",
        "+---------------------+---------------+----------------+------------+---------------+\n",
        "| c8fe3               | b519e         | 9f151          | 2022-05-01 | ERP           |\n",
        "+---------------------+---------------+----------------+------------+---------------+\n",
        "| eaeef               | 5f763         | 668f0          | 2022-05-01 | ERP           |\n",
        "+---------------------+---------------+----------------+------------+---------------+\n",
        "```\n",
        "\n",
        "The primary key here is the `field_crop_hash_key` column."
      ],
      "metadata": {
        "id": "zo2q9PfGZYI4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Accommodating changes"
      ],
      "metadata": {
        "id": "_EbaIOtu4aiu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are some examples of how changes in the source system affect the data vault models. (An insert is not presented here since it is trivial.)\n",
        "\n",
        "### 3.1. Changes in a data set\n",
        "\n",
        "_Scenario:_ Let's say we realize that tomatos don't consume 10 entites of water but 12.\n",
        "\n",
        "_Approach:_ We set the `end_date` of the current row and add a new row will the new values.\n",
        "\n",
        "_Before data changes:_\n",
        "```\n",
        "crops satelite:\n",
        "+---------------+----------+-------------------+------------+----------+---------------+-----------+\n",
        "| crop_hash_key | crop     | water_consumption | load_date  | end_date | record_source | hash_diff |\n",
        "+---------------+----------+-------------------+------------+----------+---------------+-----------+\n",
        "| b519e         | tomate   | 10                | 2022-05-01 | NULL     | ERP           | 8a3f0     |\n",
        "+---------------+----------+-------------------+------------+----------+---------------+-----------+\n",
        "...\n",
        "+---------------+----------+-------------------+------------+----------+---------------+-----------+\n",
        "```\n",
        "\n",
        "_After data changes:_\n",
        "```\n",
        "crops satelite:\n",
        "+---------------+----------+-------------------+------------+------------+---------------+-----------+\n",
        "| crop_hash_key | crop     | water_consumption | load_date  | end_date   | record_source | hash_diff |\n",
        "+---------------+----------+-------------------+------------+------------+---------------+-----------+\n",
        "| b519e         | tomate   | 10                | 2022-05-01 | 2022-05-02 | ERP           | 8a3f0     |\n",
        "+---------------+----------+-------------------+------------+------------+---------------+-----------+\n",
        "...\n",
        "+---------------+----------+-------------------+------------+------------+---------------+-----------+\n",
        "| b519e         | tomate   | 12                | 2022-05-02 | NULL       | ERP           | 8a3f0     |\n",
        "+---------------+----------+-------------------+------------+------------+---------------+-----------+\n",
        "```\n",
        "\n",
        "As you can see, the `hash_key` has not changed since this new data is now associated with the business key. Only the `end_date` on the old row has been set (which is the **only** update operation allowed in the whole data vault model) to show that the data set is no longer active.\n",
        "\n",
        "_Benefits:_\n",
        "- ✅ Tracking data changes\n",
        "- ✅ Only import differences\n",
        "\n",
        "### 3.2. Add columns\n",
        "\n",
        "_Scenario:_ Let's say we also want to save the crop height.\n",
        "\n",
        "_Approach:_ We create a new satellite table with the additional data and connect the new table with the old table using a new link table.\n",
        "\n",
        "_New tables:_\n",
        "```\n",
        "crops height satelite:\n",
        "+-----------------+-------------+------------+----------+---------------+-----------+\n",
        "| height_hash_key | crop_height | load_date  | end_date | record_source | hash_diff |\n",
        "+-----------------+-------------+------------+----------+---------------+-----------+\n",
        "| 74f10           | 30          | 2022-05-03 | NULL     | ERP           | a8c94     |\n",
        "+-----------------+-------------+------------+----------+---------------+-----------+\n",
        "| d9570           | 15          | 2022-05-03 | NULL     | ERP           | ef3a9     |\n",
        "+-----------------+-------------+------------+----------+---------------+-----------+\n",
        "\n",
        "crops - crops height link:\n",
        "+---------------------------+---------------+----------------------+------------+---------------+\n",
        "| crop_crop_height_hash_key | crop_hash_key | crop_height_hash_key | load_date  | record_source |\n",
        "+---------------------------+---------------+----------------------+------------+---------------+\n",
        "| 05610                     | b519e         | 74f10                | 2022-05-03 | ERP           |\n",
        "+---------------------------+---------------+----------------------+------------+---------------+\n",
        "| 2c61c                     | 5f763         | d9570                | 2022-05-03 | ERP           |\n",
        "+---------------------------+---------------+----------------------+------------+---------------+\n",
        "```\n",
        "\n",
        "Using this approach, we just added a new table to accommodate the change in the source schema. Everything else stays the same.\n",
        "\n",
        "_Benefits:_\n",
        "- ✅ Tracking schema changes\n",
        "- ✅ Downstream ETL processes do not need to be adjusted if they don't need the new information\n",
        "\n",
        "### 3.3. Remove columns\n",
        "\n",
        "_Scenario:_ Let's say we don't need the `water_consumption` column anymore.\n",
        "\n",
        "_Approach:_ Since all columns need to be nullable anyway, we don't need to adjust our model and can just import `NULL` values into the correct columns. But again, we will add a new row, for each data entry, in order to not destroy our historical data.\n",
        "\n",
        "_Benefits:_\n",
        "- ✅ Tracking schema changes\n",
        "- ✅ Downstream ETL processes do not need to be adjusted\n",
        "\n",
        "### 3.4. Changes relationship dimensions\n",
        "\n",
        "_Scenario:_ Let's say we want to split the second field to grow both tomatoes and cucumbers.\n",
        "\n",
        "_Approach:_ We just add another row to the link table and from now on the data vault will contain an n:m relationship.\n",
        "\n",
        "_Before relationship changes:_\n",
        "```\n",
        "crops fields link:\n",
        "+---------------------+---------------+----------------+------------+---------------+\n",
        "| field_crop_hash_key | crop_hash_key | field_hash_key | load_date  | record_source |\n",
        "+---------------------+---------------+----------------+------------+---------------+\n",
        "...\n",
        "+---------------------+---------------+----------------+------------+---------------+\n",
        "| eaeef               | 5f763         | 668f0          | 2022-05-01 | ERP           |\n",
        "+---------------------+---------------+----------------+------------+---------------+\n",
        "```\n",
        "\n",
        "_After data changes:_\n",
        "```\n",
        "crops fields link:\n",
        "+---------------------+---------------+----------------+------------+---------------+\n",
        "| field_crop_hash_key | crop_hash_key | field_hash_key | load_date  | record_source |\n",
        "+---------------------+---------------+----------------+------------+---------------+\n",
        "...\n",
        "+---------------------+---------------+----------------+------------+---------------+\n",
        "| eaeef               | 5f763         | 668f0          | 2022-05-01 | ERP           |\n",
        "+---------------------+---------------+----------------+------------+---------------+\n",
        "| f2483               | b519e         | 668f0          | 2022-05-01 | ERP           |\n",
        "+---------------------+---------------+----------------+------------+---------------+\n",
        "```\n",
        "\n",
        "_Benefits:_\n",
        "- ✅ Tracking data changes\n",
        "- ✅ Only import differences\n",
        "\n",
        "### 3.5. Remove Relationships\n",
        "\n",
        "This scenario is a more advanced one, which is why it is only covered conceptually. Generally speaking, there are two ways to cover this scenario:\n",
        "1. You can add an `end_date` to the link table. This, however, is strongly discouraged since it has multiple edge cases in which the data vault model would fail. One of these is *What if a crop is grown on a field, then not anymore and then again?* If the `field_crop_hash_key` column is generated as a random value. That is possible. However, this leads to bad performance during imports, since usually the `hash_key` of the tables is actually a hash of the important and immutable fields. If that is the `hash_key` it actually has, this approach does not work.\n",
        "2. You will need to add a new hub and satellite with metadata for the relationship and therefore for this link.\n"
      ],
      "metadata": {
        "id": "ZOLBV4guhFCk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sources\n",
        "\n",
        "- Wikipedia: https://en.wikipedia.org/wiki/Data_vault_modeling\n",
        "- https://www.sciencedirect.com/book/9780128025109/building-a-scalable-data-warehouse-with-data-vault-2-0\n",
        "- https://danlinstedt.com/wp-content/uploads/2018/06/DVModelingSpecs2-0-1.pdf"
      ],
      "metadata": {
        "id": "wVRpoaU4Tct9"
      }
    }
  ]
}