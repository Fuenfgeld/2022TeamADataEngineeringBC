{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Uebungen_Teil3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fuenfgeld/2022TeamADataEngineeringBC/blob/main/Pr%C3%A4sentationen/03-Fortgeschrittene%20Transformationen/Uebungen_Teil3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vorbereitung einlesen der Daten \n",
        "\n",
        "In diesem Abschnitt müssen Sie nichts machen. Dieser dient nur für das Einlesen und die Bereitstellung der Daten für die folgenden Übungen. "
      ],
      "metadata": {
        "id": "zopt-B7jUV16"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GfC-OQBE_bh",
        "outputId": "2084d0b4-76db-4add-a846-1edead70cf2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 35 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Collecting pysqlite3\n",
            "  Downloading pysqlite3-0.4.7.tar.gz (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 14.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Building wheels for collected packages: pyspark, pysqlite3\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=533babc13ece91df95dc66cce485115480bdf6d0ae5a46080c63941e3d6ac5b6\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "  Building wheel for pysqlite3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pysqlite3: filename=pysqlite3-0.4.7-cp37-cp37m-linux_x86_64.whl size=132892 sha256=04f79b341bd67b1d774723e2dbcdcb8dacf82a11dee8b1e0df2a59e760416a4b\n",
            "  Stored in directory: /root/.cache/pip/wheels/e5/bf/e1/b92ae6794ca15c7dcc2b1f8068ebb3f86e6affa5c0fe5e8f40\n",
            "Successfully built pyspark pysqlite3\n",
            "Installing collected packages: py4j, pysqlite3, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1 pysqlite3-0.4.7\n"
          ]
        }
      ],
      "source": [
        "# Bibliotheken einmalig installieren\n",
        "!pip install pyspark pandas pysqlite3 "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Angabe der Daten für den Pfad\n",
        "!wget -O create_data_advacend.py https://raw.githubusercontent.com/Fuenfgeld/2022TeamADataEngineeringBC/36-pr%C3%A4sentation-fortgeschrittene-transaktionen/Pr%C3%A4sentationen/03-Fortgeschrittene%20Transformationen/create_data_advacend.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-23uk-88H6R",
        "outputId": "63a00b58-58ea-402b-926e-1b9779fbde1a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-12 14:15:48--  https://raw.githubusercontent.com/Fuenfgeld/2022TeamADataEngineeringBC/36-pr%C3%A4sentation-fortgeschrittene-transaktionen/Pr%C3%A4sentationen/03-Fortgeschrittene%20Transformationen/create_data_advacend.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11341 (11K) [text/plain]\n",
            "Saving to: ‘create_data_advacend.py’\n",
            "\n",
            "\rcreate_data_advacen   0%[                    ]       0  --.-KB/s               \rcreate_data_advacen 100%[===================>]  11.08K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-05-12 14:15:48 (80.5 MB/s) - ‘create_data_advacend.py’ saved [11341/11341]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import der nötigen Packete\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import pyspark.sql.functions as func\n",
        "import os\n",
        "\n",
        "os.system(\"python3 create_data_advacend.py\")"
      ],
      "metadata": {
        "id": "-wrNz_wMFTYI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d4aaf6f-8ac5-4a91-a477-da9fe7142513"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## (Py)Spark starten\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.getOrCreate()"
      ],
      "metadata": {
        "id": "IcR_IIdyVAwo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Datei Corn einlesen & in Spark-Dataframe schreiben\n",
        "df_corn = spark.read.option(\"multiline\",True).json('Corn.json')\n",
        "df_corn.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZS1ALDxs8KlI",
        "outputId": "15dcb504-8277-41a2-b3fa-3b2ec027f5e7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+-------+-----------------+----+-------------+\n",
            "|  crop|field|revenue|water_consumption|week|yield_per_sqm|\n",
            "+------+-----+-------+-----------------+----+-------------+\n",
            "|barley|    8|      0|               12|   1|            0|\n",
            "|barley|    8|      0|               10|   2|            0|\n",
            "|barley|    8|      0|               12|   3|            0|\n",
            "|barley|    8|     35|               14|   4|           10|\n",
            "|barley|    8|     50|               14|   5|           25|\n",
            "|barley|    8|     40|               18|   6|           15|\n",
            "|barley|    8|     60|               12|   7|           30|\n",
            "|  corn|   10|      0|               10|   1|            0|\n",
            "|  corn|   10|      0|               12|   2|            0|\n",
            "|  corn|   10|     30|               20|   3|           25|\n",
            "|  corn|   10|     60|               26|   4|           25|\n",
            "|  corn|   10|    150|               24|   5|           25|\n",
            "|  corn|   10|    100|               10|   6|           25|\n",
            "|  corn|   10|    150|               15|   7|            0|\n",
            "|  oats|    9|      0|               15|   1|            0|\n",
            "|  oats|    9|      0|               25|   2|            0|\n",
            "|  oats|    9|    150|               15|   3|           60|\n",
            "|  oats|    9|    150|               25|   4|           60|\n",
            "|  oats|    9|    150|               25|   5|           60|\n",
            "|  oats|    9|    120|               15|   6|           40|\n",
            "+------+-----+-------+-----------------+----+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Datenbankdaten in Dataframe schreiben\n",
        "connection_obj = sqlite3.connect('Diddly_Squat_Farm.db')\n",
        "cursor_obj = connection_obj.cursor()\n",
        "\n",
        "# Tabelle Fields ausgeben\n",
        "for row in cursor_obj.execute('SELECT * FROM fields'):\n",
        "        print(row)\n",
        "\n",
        "# Tabelle Fields in Dataframe df_fields schreiben\n",
        "df_fields = pd.read_sql_query(\"SELECT * FROM fields\", connection_obj)\n",
        "print('\\n\\nDies ist das erzeugte Dataframe:\\n\\n', df_fields)\n",
        "\n",
        "connection_obj.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YP7ra-l3WSKr",
        "outputId": "d0f8c89a-5486-40b3-feee-822f3b5ffd01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5, 'Barn Ground', 10)\n",
            "(6, 'Bank', 10)\n",
            "(7, 'Far Brossler', 20)\n",
            "(8, 'Middle Broom', 20)\n",
            "(9, 'Chalks', 25)\n",
            "(10, 'Big Broom ', 60)\n",
            "\n",
            "\n",
            "Dies ist das erzeugte Dataframe:\n",
            "\n",
            "    field_id    field_name  area_in_sqm\n",
            "0         5   Barn Ground           10\n",
            "1         6          Bank           10\n",
            "2         7  Far Brossler           20\n",
            "3         8  Middle Broom           20\n",
            "4         9        Chalks           25\n",
            "5        10    Big Broom            60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#DataFrame für Datenbank erzeugen\n",
        "df_fields= spark.createDataFrame(df_fields)\n",
        "df_fields.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkH8SqGOWVQe",
        "outputId": "2df70d5f-005e-4aec-fe32-3eff24fa4714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------------+-----------+\n",
            "|field_id|  field_name|area_in_sqm|\n",
            "+--------+------------+-----------+\n",
            "|       5| Barn Ground|         10|\n",
            "|       6|        Bank|         10|\n",
            "|       7|Far Brossler|         20|\n",
            "|       8|Middle Broom|         20|\n",
            "|       9|      Chalks|         25|\n",
            "|      10|  Big Broom |         60|\n",
            "+--------+------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nachdem nun alle Daten geladen wurden können Sie anschließend mit den Übungen beginnen."
      ],
      "metadata": {
        "id": "JQTRNXS1Vd1l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Übungen für Fortgeschrittene \n",
        "\n",
        "In dieser Übung müssen Sie Jeremy tatkräftig unter die Arme greifen. \n",
        "Nachdem wir bereits Ihm bereits bei dem Anbau des Obst und Gemüse geholen haben, müssen Sie nun für in die Daten für das Getreide auswerten.\n",
        "\n",
        "Hierfür müssen Sie folgend vorgehen:\n",
        "\n",
        "1.   Helfen Sie Jeremy dabei sich einen Überblick über die Daten zu verschaffen in dem Sie JOIN verwerden.\n",
        "2.   Berechnen Sie für die jeweilge Getreideart den Wasserverbrauch, Ertrag pro Fläche sowie die Einnahmen.\n",
        "\n",
        "\n",
        "\n",
        "__________________________________________________________________________\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FPlrbGG7CmG1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Um Jeremy helfen zu können verschaffen Sie sich zunächst einen Überblick über die Daten."
      ],
      "metadata": {
        "id": "kOP_N92hHCDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_fields.???\n",
        "df_corn.???"
      ],
      "metadata": {
        "id": "GawHQ1z_G9I6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "0aae6a23-5dee-46a8-9364-29cff9a95997"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-21-59eeeb92e3e1>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    df_fields.???\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verknüpfen Sie anschließend die zwei Tabellen miteinander. Wählen Sie hierfür die geeignete Join-Bedingung. "
      ],
      "metadata": {
        "id": "7uosHkloqBu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gesamt_join = df_corn.join(???, ??? ==  ???,\"???\")\n",
        "gesamt_join.show()"
      ],
      "metadata": {
        "id": "A_7gmwzzpWE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Um die Wirtschaftlichkeit unseres Unternehmen zu prüfen, möchte Jeremy sich den gesamten Ertrag pro Fläch für die jeweiligen Getreidesorte wissen. Helfen Sie Jeremy dabei in dem Sie:\n",
        "\n",
        "+  Die Spalten des Ertrag pro m² mit der Fläche in m² multiplizieren um den gesamten Ertrag pro Fläche zu erhalten \n",
        "+ Erzeugen Sie eine neue Spalte im DataFrame für das Ergebnis\n",
        "+ Tipp: hierfür können Sie die Funcktion col der Sparkfunctions verwenden\n",
        "\n"
      ],
      "metadata": {
        "id": "ae5T4zd7pk5F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gesamt_join = gesamt_join.withColumn(\"???\", func.col(\"???\") * func.col(\"???\"))\n",
        "gesamt_join.show()\n"
      ],
      "metadata": {
        "id": "NAnuWwdwpizi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nutzen Sie **groupby()** Bedingung sowie die Sparkfuntions **sum** um Jeremy eine Übersicht der Einnahmen, Wasserverbrauchs und dem Ertrag pro Fläche des jeweiligen Getreide zu verschaffen.\n",
        "\n"
      ],
      "metadata": {
        "id": "v7AzyzkdwC5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gesamt_ertrag =  gesamt_join.groupBy(\"???\").agg(???, ????, ???)\n",
        "gesamt_ertrag.show()"
      ],
      "metadata": {
        "id": "dmz5ckT0vzrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nachdem wir den Ertrag für die einzelnen Getreidesorten kennen, müssen wir Jeremy bei der Ermittelung des Gewinn je Lebensmittel unter die Arme greifen.\n",
        "\n",
        "+ Hierfür benötigen wir die zuvor ermittelten Liter je Sorte welche wir mit dem Wert von 0.2 Cent verrechnen. \n",
        " \n",
        "+ Anschließend müssen noch die Erwerbskosten für die  Pflanzensamen miteinbeziehen um unsere Produktionskosten zu erhalten.\n",
        "  >Kosten für Samen :\n",
        "  + Mais = 5 Cent\n",
        "  + Hafer = 10 Cent\n",
        "  + Roggen = 20 Cent \n",
        "\n",
        "\n",
        "+ Geben Sie das Ergebnis absteigend an. "
      ],
      "metadata": {
        "id": "JFj7a_pnv1oO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Die folgende Codezeile können Sie einfach ausführen um mit den Übungen fortzufahren."
      ],
      "metadata": {
        "id": "NjP287nU1D9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window as W\n",
        "rating = [5,10,20]\n",
        "seed_cost = spark.createDataFrame([(l,) for l in rating], ['cost_of_seed'])\n",
        "gesamt_ertrag = gesamt_ertrag.withColumn(\"idx\", func.monotonically_increasing_id())\n",
        "seed_cost = seed_cost.withColumn(\"idx\", func.monotonically_increasing_id())\n",
        "gesamt_ertrag.show()\n",
        "\n",
        "windowSpec = W.orderBy(\"idx\")\n",
        "gesamt_ertrag = gesamt_ertrag.withColumn(\"idx\", func.row_number().over(windowSpec))\n",
        "seed_cost = seed_cost.withColumn(\"idx\", func.row_number().over(windowSpec))\n",
        "seed_cost.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "V4RDD2cjohoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nun sind Sie wieder gefragt. Joinen Sie die beiden Tabellen um mit der Ermittlung der Produktionskosten weiterzufahren. "
      ],
      "metadata": {
        "id": "u89Erbjx03Qd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gesamt_ertrag = gesamt_ertrag.join(???, ??? == ???).drop(\"idx\")\n",
        "gesamt_ertrag.show()"
      ],
      "metadata": {
        "id": "wvbXrE750STQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "gesamt_ertrag = gesamt_ertrag.withColumn(\"revenue_after_water_cost\", ??? - (???\"* 0.02))\n",
        "gesamt_ertrag = gesamt_ertrag.withColumn(\"netto_revenue\",func.col(\"revenue_after_water_cost\") - func.col(\"cost_of_seed\"))\n",
        "gesamt_ertrag.orderBy(col(\"netto_revenue\").???).show() #desc oder asc"
      ],
      "metadata": {
        "id": "iedwMtJC1RNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Um auch für das Getreide in unserem Hofladen gewinnbringend vertreiben können, müssen wir Jeremy bei der Preisfindung unterstützen. \n",
        "\n",
        "Die Einnahmen sind bisher in Pence angegeben Rechnenen Sie diese in Pfund um.\n",
        "\n",
        ">> Randinformationen:\n",
        "*   Ein Pfund (£) hat 100 Pence (p).\n",
        "*   Für den Mindestverkaufspreis müssen unsere Getreidesorten noch mit einer Mehrwertsteuer von 19% besteuert werden.\n",
        "* Für einen lukrativen Verkaufspreis müssen wir den Nettopreis mit 59% besteuern\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "+ Verwenden Sie für die Preisfindung Lambda-Funktionen. Welche der beiden Variante Sie verwenden bleibt Ihnen überlassen. \n",
        "\n",
        "+ Ermitteln Sie hierfür den Preis pro Stück und erzeugen hierfür eine neue Spalte in dem Dataframe"
      ],
      "metadata": {
        "id": "z1V2EzJA3J3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd2 = gesamt_ertrag.rdd.map(lambda x: (???, ???*1.19*0.01, ???*1.59*0.01)) \n",
        "cost_overview = rdd2.toDF([\"Crop\",\"min_selling_price_per_piece\", \"lucrative_selling_price\"])\n",
        "cost_overview = cost_overview.withColumn(\"min_selling_price_per_piece\", func.round(cost_overview[\"min_selling_price_per_piece\"], 2)).withColumn(\"lucrative_selling_price\", func.round(cost_overview[\"lucrative_selling_price\"], 2))\n",
        "cost_overview.withColumn(\"currency\", func.lit(\"£\")).orderBy(col(\"lucrative_selling_price\").desc()).show()"
      ],
      "metadata": {
        "id": "RYjUbd0S3x4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# By Calling function\n",
        "def calc_func(x):\n",
        "    Crop = ???\n",
        "    Netto_Revenue = ???\n",
        "    min_selling_price_per_piece = ???1.19*0.01\n",
        "    lucrative_selling_price = ???1.59*0.01\n",
        "    return (???, ???, ???)\n",
        "\n",
        "rdd_process=gesamt_ertrag.rdd.map(lambda x: ???)\n",
        "cost_overview_with_func = rdd_process.toDF([\"Crop\",\"min_selling_price_per_piece\", \"lucrative_selling_price\"])\n",
        "cost_overview_with_func = cost_overview_with_func.withColumn(\"min_selling_price_per_piece\", func.round(cost_overview_with_func[\"min_selling_price_per_piece\"], 2)).withColumn(\"lucrative_selling_price\", func.round(cost_overview_with_func[\"lucrative_selling_price\"], 2))\n",
        "cost_overview_with_func.withColumn(\"currency\", func.lit(\"£\")).orderBy(col(\"lucrative_selling_price\").desc()).show()\n"
      ],
      "metadata": {
        "id": "A1hODm_E6iaN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}